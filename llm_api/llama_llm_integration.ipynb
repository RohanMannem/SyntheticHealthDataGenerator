{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from prompts import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve API key\n",
    "with open(\"../api_keys.json\", \"r\") as file:\n",
    "    api_keys = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = api_keys.get(\"Llama\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = api_key,\n",
    "    base_url = \"https://api.llama-api.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are generating synthetic healthcare data for a research project aiming to evaluate the realism and utility of synthetic datasets. The data must adhere to the following schema and meet the highest standards of quality, diversity, and logical coherence:\n",
      "\n",
      "Schema:\n",
      "- Name: string (e.g., \"Alex Smith\"; ensure diversity across names)\n",
      "- Age: integer (0-100; follow a realistic demographic distribution, e.g., more adults than children)\n",
      "- Gender: categorical (values: \"male\", \"female\", \"other\"; reflect real-world proportions)\n",
      "- Blood Type: categorical (values: \"A\", \"B\", \"AB\", \"O\"; realistic distribution based on population statistics)\n",
      "- Medical Condition: string (e.g., \"diabetes\", \"flu\", \"hypertension\"; include a mix of common and rare conditions)\n",
      "- Date of Admission: string (format: \"YYYY-MM-DD\"; ensure temporal coherence)\n",
      "- Doctor: string (e.g., \"Dr. Patel\"; match specialization to Medical Condition)\n",
      "- Hospital: string (e.g., \"Metropolitan Health Center\"; maintain logical variety in hospital names)\n",
      "- Insurance Provider: string (e.g., \"Cigna\", \"United Healthcare\")\n",
      "- Billing Amount: float (range: 100.0â€“50,000.0; introduce realistic outliers and variability)\n",
      "- Room Number: integer (ensure logical sequencing within hospitals)\n",
      "- Admission Type: categorical (values: \"emergency\", \"elective\", \"urgent\"; ensure realistic distributions based on Medical Condition)\n",
      "- Discharge Date: string (format: \"YYYY-MM-DD\"; ensure coherence with Admission Date)\n",
      "- Medication: string (e.g., \"metformin\", \"antibiotics\"; specific to Medical Condition)\n",
      "- Test Results: string (e.g., \"HbA1c high\", \"viral test positive\"; ensure relevance to Medical Condition)\n",
      "\n",
      "Your response must:\n",
      "1. Maintain diversity and realism across all attributes.\n",
      "2. Ensure logical relationships between attributes (e.g., higher Billing Amount for emergency cases).\n",
      "3. Introduce outliers and edge cases (e.g., patients over 90 years old with complex medical histories).\n",
      "4. Present the data in a clean JSON-like format, one object per row.\n",
      "\n",
      "Focus on making the data statistically similar to real-world healthcare datasets and suitable for training machine learning models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(advanced_developer_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 10 rows of synthetic healthcare data.\n"
     ]
    }
   ],
   "source": [
    "print(basic_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_data = []\n",
    "for seed in range(100):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3.1-70b\",\n",
    "        store=True,\n",
    "        messages=[\n",
    "                {\n",
    "                    \"role\": \"developer\",\n",
    "                    \"content\": advanced_developer_message\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": basic_prompts[0]\n",
    "                }\n",
    "            ],\n",
    "        seed=seed\n",
    "        \n",
    "    )\n",
    "    full_data.append(response)\n",
    "\n",
    "\n",
    "# print(response.model_dump_json(indent=2))\n",
    "# print('-----------')\n",
    "# print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created at: ../full_data/llama_advanced_dev_message_w_basic_prompt_records.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder and file paths\n",
    "folder_path = \"../full_data\"\n",
    "file_name = \"llama_advanced_dev_message_w_basic_prompt_records.txt\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    for item in full_data:\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n",
    "print(f\"File created at: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id=None, choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are 10 rows of synthetic healthcare data that adhere to the provided schema and meet the requirements for diversity, realism, and logical coherence:\\n\\n```\\n[\\n  {\\n    \"Name\": \"Emily Chen\",\\n    \"Age\": 32,\\n    \"Gender\": \"female\",\\n    \"Blood Type\": \"A\",\\n    \"Medical Condition\": \"hypertension\",\\n    \"Date of Admission\": \"2022-01-15\",\\n    \"Doctor\": Dr. Lee (Cardiology),\\n    Hospital', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1736266934, model='llama3.1-70b', object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=142, prompt_tokens=64, total_tokens=206, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(full_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'finish_reason': 'length',\n",
       "   'index': 0,\n",
       "   'message': {'content': 'Here are 10 rows of synthetic healthcare data that adhere to the provided schema and meet the requirements for diversity, realism, and logical coherence:\\n\\n```\\n[\\n  {\\n    \"Name\": \"Emily Chen\",\\n    \"Age\": 32,\\n    \"Gender\": \"female\",\\n    \"Blood Type\": \"A\",\\n    \"Medical Condition\": \"hypertension\",\\n    \"Date of Admission\": \"2022-01-15\",\\n    \"Doctor\": Dr. Lee (Cardiology),\\n    Hospital',\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1736266934,\n",
       " 'model': 'llama3.1-70b',\n",
       " 'usage': {'completion_tokens': 142, 'prompt_tokens': 64, 'total_tokens': 206}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatcompletion_to_dict(chat_completion):\n",
    "    \"\"\"Recursively convert a ChatCompletion object into a JSON-serializable dictionary.\"\"\"\n",
    "    if isinstance(chat_completion, list):\n",
    "        return [chatcompletion_to_dict(item) for item in chat_completion]\n",
    "    elif hasattr(chat_completion, \"__dict__\"):  # For objects with attributes\n",
    "        return {\n",
    "            key: chatcompletion_to_dict(value)\n",
    "            for key, value in vars(chat_completion).items()\n",
    "            if value is not None  # Skip None values\n",
    "        }\n",
    "    elif isinstance(chat_completion, dict):  # Handle nested dictionaries\n",
    "        return {key: chatcompletion_to_dict(value) for key, value in chat_completion.items()}\n",
    "    else:\n",
    "        return chat_completion  # Return base types as-is\n",
    "    \n",
    "test = chatcompletion_to_dict(full_data[0])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_serialized = []\n",
    "for i in full_data:\n",
    "    full_data_serialized.append(chatcompletion_to_dict(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created at: ../full_data/llama_advanced_dev_message_w_basic_prompt_records.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder and file paths\n",
    "folder_path = \"../full_data\"\n",
    "file_name = \"llama_advanced_dev_message_w_basic_prompt_records.json\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(full_data_serialized, file)\n",
    "\n",
    "print(f\"File created at: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id=None, choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are ten rows of synthetic healthcare data, each row representing a patient\\'s information in JSON-like format:\\n\\n```\\n[\\n  {\\n    \"Name\": \"Evelyn Thompson\",\\n    \"Age\": 62,\\n    \"Gender\": \"female\",\\n    \"Blood Type\": \"O\",\\n    \"Medical Condition\": \"hypertension\",\\n    \"Date of Admission\": \"2022-01-10\",\\n    \"Doctor\": \"Dr. Rodriguez (Cardiologist)\",\\n    \"Hospital\": \"', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1736275582, model='llama3.1-405b', object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=142, prompt_tokens=64, total_tokens=206, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"llama3.1-405b\",\n",
    "        store=True,\n",
    "        messages=[\n",
    "                {\n",
    "                    \"role\": \"developer\",\n",
    "                    \"content\": advanced_developer_message\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": basic_prompts[0]\n",
    "                }\n",
    "            ],\n",
    "        stop=None\n",
    "    )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are ten rows of synthetic healthcare data, each row representing a patient\\'s information in JSON-like format:\\n\\n```\\n[\\n  {\\n    \"Name\": \"Evelyn Thompson\",\\n    \"Age\": 62,\\n    \"Gender\": \"female\",\\n    \"Blood Type\": \"O\",\\n    \"Medical Condition\": \"hypertension\",\\n    \"Date of Admission\": \"2022-01-10\",\\n    \"Doctor\": \"Dr. Rodriguez (Cardiologist)\",\\n    \"Hospital\": \"'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
